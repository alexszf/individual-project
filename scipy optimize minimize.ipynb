{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import ffmpeg, numpy as np, matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import scipy.optimize\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in audio from file\n",
    "def readAudio(filename):\n",
    "    try:\n",
    "        input_audio, err = (ffmpeg\n",
    "                    .input(filename)\n",
    "                    .output('-', format='s16le', acodec='pcm_s16le', ac=1, ar='48k')\n",
    "                    .overwrite_output()\n",
    "                    .run(capture_stdout=True, capture_stderr=True)\n",
    "                    )\n",
    "    except ffmpeg.Error as e:\n",
    "        print(e.stderr)\n",
    "    read_audio = np.fromstring(input_audio, dtype=np.int16).astype(np.float16)\n",
    "    return read_audio\n",
    "\n",
    "#read in audio from file but add eq\n",
    "def readAudioWithEQ(filename):\n",
    "    try:\n",
    "        input_audio, err = (ffmpeg\n",
    "                    .input(filename)\n",
    "                    .filter(\"equalizer\", f=1000, t='q', w=100, g=10)\n",
    "                    .output('-', format='s16le', acodec='pcm_s16le', ac=1, ar='48k')\n",
    "                    .overwrite_output()\n",
    "                    .run(capture_stdout=True, capture_stderr=True)\n",
    "                    )\n",
    "    except ffmpeg.Error as e:\n",
    "        print(e.stderr)\n",
    "    read_audio = np.fromstring(input_audio, dtype=np.int16).astype(np.float16)\n",
    "    return read_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(audio_1, audio_2):\n",
    "    f_1, t_1, spec_1 = scipy.signal.spectrogram(audio_1, fs=48000)\n",
    "    f_2, t_2, spec_2 = scipy.signal.spectrogram(audio_2, fs=48000)\n",
    "    return np.linalg.norm(spec_1[:-1] - spec_2[:-1])\n",
    "\n",
    "def apply_effect(params, clean_audio):\n",
    "    r_gain = params[0]\n",
    "    r_freq = 1000\n",
    "    r_width = 100\n",
    "    x = np.round(clean_audio).astype('int16')\n",
    "    new_audio = None\n",
    "    try:\n",
    "        #define graph\n",
    "        process_audio = (ffmpeg\n",
    "            .input('pipe:', format='s16le', acodec='pcm_s16le', ac=1, ar='48k')\n",
    "            .filter(\"equalizer\", f=r_freq, t='q', w=r_width, g=r_gain)\n",
    "            .output('pipe:', format='s16le', acodec='pcm_s16le', ac=1, ar='48k')\n",
    "            .run_async(pipe_stdin=True, pipe_stdout=True)\n",
    "        )\n",
    "        #pipe in the audio\n",
    "        process_audio.stdin.write(\n",
    "            clean_audio\n",
    "            .astype(np.int16)\n",
    "            .tobytes()\n",
    "        )\n",
    "        process_audio.stdin.close()\n",
    "        signal = process_audio.stdout.read()\n",
    "        new_audio = np.fromstring(signal, dtype=np.int16).astype(np.float16)\n",
    "        process_audio.stdout.close()\n",
    "    except ffmpeg.Error as e:\n",
    "        print(e.stderr)\n",
    "        sys.exit(1)\n",
    "    return new_audio\n",
    "\n",
    "def func(params, target_audio, clean_audio):\n",
    "    new_audio = apply_effect(params, clean_audio)\n",
    "    #return distance\n",
    "    return compute_distance(new_audio, target_audio)\n",
    "\n",
    "#args = [target_audio, clean_audio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_audio = readAudioWithEQ(\"../recordings/sample_ffmpeg.wav\")\n",
    "clean_audio = readAudio(\"../recordings/sample_ffmpeg.wav\")\n",
    "target_audio = target_audio[96000:144000]\n",
    "clean_audio = clean_audio[96000:144000]\n",
    "\n",
    "#params = [gain]\n",
    "params = [0.7]\n",
    "result = scipy.optimize.minimize(func, params,\n",
    "                                 args=(target_audio, clean_audio),\n",
    "                                 method='nelder-mead',\n",
    "                                 options={'disp':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_distance(clean_audio[96000:144000], target_audio[96000:144000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(clean_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
